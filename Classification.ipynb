{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"Popular_Clean.csv\")\n",
    "df2 = pd.read_csv(\"Song_Analytics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>...</th>\n",
       "      <th>highest_peak_value</th>\n",
       "      <th>normalized_likes</th>\n",
       "      <th>normalized_views</th>\n",
       "      <th>normalized_us_hit</th>\n",
       "      <th>normalized_high_peak</th>\n",
       "      <th>likes_per_day</th>\n",
       "      <th>views_per_day</th>\n",
       "      <th>genre_averaged_likes</th>\n",
       "      <th>normalized_num_peak_periods</th>\n",
       "      <th>popularity_score_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.00146</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>0.334</td>\n",
       "      <td>171.005</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>16.078045</td>\n",
       "      <td>20.463609</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.015113</td>\n",
       "      <td>0.025767</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>43.660471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dance Monkey</td>\n",
       "      <td>Tones And I</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.0937</td>\n",
       "      <td>0.69000</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.514</td>\n",
       "      <td>98.029</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.554820</td>\n",
       "      <td>21.452550</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>0.014216</td>\n",
       "      <td>0.029205</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>41.465744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        track_name  artist_name  danceability  energy  speechiness  \\\n",
       "0  Blinding Lights   The Weeknd         0.514   0.730       0.0598   \n",
       "1     Dance Monkey  Tones And I         0.824   0.587       0.0937   \n",
       "\n",
       "   acousticness  instrumentalness  liveness  valence    tempo  ...  \\\n",
       "0       0.00146          0.000095    0.0897    0.334  171.005  ...   \n",
       "1       0.69000          0.000105    0.1490    0.514   98.029  ...   \n",
       "\n",
       "   highest_peak_value normalized_likes  normalized_views  normalized_us_hit  \\\n",
       "0               100.0        16.078045         20.463609           3.258097   \n",
       "1                12.0        16.554820         21.452550           2.484907   \n",
       "\n",
       "   normalized_high_peak likes_per_day views_per_day  genre_averaged_likes  \\\n",
       "0              4.615121      0.011874      0.015113              0.025767   \n",
       "1              2.564949      0.010971      0.014216              0.029205   \n",
       "\n",
       "  normalized_num_peak_periods  popularity_score_scaled  \n",
       "0                    0.333333                43.660471  \n",
       "1                    0.111111                41.465744  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>tempo</th>\n",
       "      <th>mean_zcr</th>\n",
       "      <th>median_zcr</th>\n",
       "      <th>std_zcr</th>\n",
       "      <th>max_zcr</th>\n",
       "      <th>aboveThr_zcr</th>\n",
       "      <th>mean_sc</th>\n",
       "      <th>median_sc</th>\n",
       "      <th>std_sc</th>\n",
       "      <th>...</th>\n",
       "      <th>contrast_del_mean</th>\n",
       "      <th>contrast_avg_sd</th>\n",
       "      <th>Tone1</th>\n",
       "      <th>Tone2</th>\n",
       "      <th>Tone3</th>\n",
       "      <th>Tone4</th>\n",
       "      <th>Tone5</th>\n",
       "      <th>Tone6</th>\n",
       "      <th>Tone_deltaMean</th>\n",
       "      <th>Tone_avg_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0800 HEAVEN</td>\n",
       "      <td>143.554688</td>\n",
       "      <td>0.0918</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.6323</td>\n",
       "      <td>0.4358</td>\n",
       "      <td>2196.7699</td>\n",
       "      <td>2259.6592</td>\n",
       "      <td>862.0266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6804</td>\n",
       "      <td>6.128429</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.009060</td>\n",
       "      <td>0.106067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 2 3 feat Jason Derulo  De La Ghetto</td>\n",
       "      <td>95.703125</td>\n",
       "      <td>0.1278</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>0.6041</td>\n",
       "      <td>2811.9937</td>\n",
       "      <td>2768.6767</td>\n",
       "      <td>1057.0624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7764</td>\n",
       "      <td>6.554386</td>\n",
       "      <td>0.1012</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.008302</td>\n",
       "      <td>0.086733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              track_name       tempo  mean_zcr  median_zcr  \\\n",
       "0                            0800 HEAVEN  143.554688    0.0918      0.0913   \n",
       "1  1 2 3 feat Jason Derulo  De La Ghetto   95.703125    0.1278      0.1172   \n",
       "\n",
       "   std_zcr  max_zcr  aboveThr_zcr    mean_sc  median_sc     std_sc  ...  \\\n",
       "0   0.0527   0.6323        0.4358  2196.7699  2259.6592   862.0266  ...   \n",
       "1   0.0813   0.6621        0.6041  2811.9937  2768.6767  1057.0624  ...   \n",
       "\n",
       "   contrast_del_mean  contrast_avg_sd   Tone1   Tone2   Tone3   Tone4   Tone5  \\\n",
       "0             0.6804         6.128429  0.1183  0.1248  0.1614  0.1270  0.0527   \n",
       "1             0.7764         6.554386  0.1012  0.0931  0.1172  0.1136  0.0526   \n",
       "\n",
       "    Tone6  Tone_deltaMean  Tone_avg_sd  \n",
       "0  0.0522        0.009060     0.106067  \n",
       "1  0.0427        0.008302     0.086733  \n",
       "\n",
       "[2 rows x 71 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging 'popularity_score_scaled' and 'time_frame' from df1 into df2\n",
    "df_model = df2.merge(df1[['track_name', 'popularity_score_scaled', 'time_frame']], \n",
    "                       on='track_name', \n",
    "                       how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>tempo</th>\n",
       "      <th>mean_zcr</th>\n",
       "      <th>median_zcr</th>\n",
       "      <th>std_zcr</th>\n",
       "      <th>max_zcr</th>\n",
       "      <th>aboveThr_zcr</th>\n",
       "      <th>mean_sc</th>\n",
       "      <th>median_sc</th>\n",
       "      <th>std_sc</th>\n",
       "      <th>...</th>\n",
       "      <th>Tone1</th>\n",
       "      <th>Tone2</th>\n",
       "      <th>Tone3</th>\n",
       "      <th>Tone4</th>\n",
       "      <th>Tone5</th>\n",
       "      <th>Tone6</th>\n",
       "      <th>Tone_deltaMean</th>\n",
       "      <th>Tone_avg_sd</th>\n",
       "      <th>popularity_score_scaled</th>\n",
       "      <th>time_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0800 HEAVEN</td>\n",
       "      <td>143.554688</td>\n",
       "      <td>0.0918</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.6323</td>\n",
       "      <td>0.4358</td>\n",
       "      <td>2196.7699</td>\n",
       "      <td>2259.6592</td>\n",
       "      <td>862.0266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.009060</td>\n",
       "      <td>0.106067</td>\n",
       "      <td>53.814449</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 2 3 feat Jason Derulo  De La Ghetto</td>\n",
       "      <td>95.703125</td>\n",
       "      <td>0.1278</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>0.6041</td>\n",
       "      <td>2811.9937</td>\n",
       "      <td>2768.6767</td>\n",
       "      <td>1057.0624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1012</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.008302</td>\n",
       "      <td>0.086733</td>\n",
       "      <td>54.638400</td>\n",
       "      <td>2117.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              track_name       tempo  mean_zcr  median_zcr  \\\n",
       "0                            0800 HEAVEN  143.554688    0.0918      0.0913   \n",
       "1  1 2 3 feat Jason Derulo  De La Ghetto   95.703125    0.1278      0.1172   \n",
       "\n",
       "   std_zcr  max_zcr  aboveThr_zcr    mean_sc  median_sc     std_sc  ...  \\\n",
       "0   0.0527   0.6323        0.4358  2196.7699  2259.6592   862.0266  ...   \n",
       "1   0.0813   0.6621        0.6041  2811.9937  2768.6767  1057.0624  ...   \n",
       "\n",
       "    Tone1   Tone2   Tone3   Tone4   Tone5   Tone6  Tone_deltaMean  \\\n",
       "0  0.1183  0.1248  0.1614  0.1270  0.0527  0.0522        0.009060   \n",
       "1  0.1012  0.0931  0.1172  0.1136  0.0526  0.0427        0.008302   \n",
       "\n",
       "   Tone_avg_sd  popularity_score_scaled  time_frame  \n",
       "0     0.106067                53.814449       178.0  \n",
       "1     0.086733                54.638400      2117.0  \n",
       "\n",
       "[2 rows x 73 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_model.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlwElEQVR4nO3dcXCU9Z3H8c9ustkkQBITh2xyJpLrcQMKFUskRpw7LYGIqKBcPTS9Sykj1zZUMTNVYg0NIA1yPcqBFE6nxXGOVOucUqUWzAULxxhCCOIVtRFHThxpwrW5ZIGUZc3+7o8OO65BSODZ3d8u79cME57f89vffvfL8uQzz+6z6zLGGAEAAFjEHe8CAAAAPo+AAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwTmq8C7gYoVBIx44d06hRo+RyueJdDgAAGAJjjE6cOKHCwkK53ec/R5KQAeXYsWMqKiqKdxkAAOAifPzxx7rqqqvOOychA8qoUaMk/fkBZmVlnXduMBjU66+/rhkzZsjj8cSivMsePY8t+h179Dy26HfsRavnfr9fRUVF4d/j55OQAeXsyzpZWVlDCiiZmZnKysriiR0j9Dy26Hfs0fPYot+xF+2eD+XtGbxJFgAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6qfEuAEB0jVnyq3iXMGz/s2pWvEsAEGecQQEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrpMa7ACCRjFnyq3iXMIg3xWj1FGlCww4FBlzxLgcAHMEZFAAAYJ1hB5Tdu3frzjvvVGFhoVwul7Zu3RreFwwG9eijj2rixIkaMWKECgsL9Y//+I86duxYxBo9PT2qqqpSVlaWcnJytGDBAp08efKSHwwAAEgOww4op06d0nXXXacNGzYM2tff368DBw6ovr5eBw4c0EsvvaTOzk7dddddEfOqqqr0zjvvqLm5Wdu2bdPu3bu1cOHCi38UAAAgqQz7PSgzZ87UzJkzz7kvOztbzc3NEWNPPfWUpkyZoqNHj6q4uFjvvfeetm/frvb2dpWWlkqS1q9fr9tvv10/+tGPVFhYeBEPAwAAJJOov0m2r69PLpdLOTk5kqTW1lbl5OSEw4kkVVRUyO12q62tTXffffegNQKBgAKBQHjb7/dL+vNLSsFg8Lz3f3b/hebBOcncc2+KiXcJg3jdJuJnMrD9uZPMz3Eb0e/Yi1bPh7NeVAPK6dOn9eijj+q+++5TVlaWJKmrq0ujR4+OLCI1Vbm5uerq6jrnOo2NjVq2bNmg8ddff12ZmZlDquXzZ3YQfcnY89VT4l3BF1tRGop3CY557bXX4l3CkCTjc9xm9Dv2nO55f3//kOdGLaAEg0Hde++9MsZo48aNl7RWXV2damtrw9t+v19FRUWaMWNGOPicr47m5mZNnz5dHo/nkurA0CRzzyc07Ih3CYN43UYrSkOq3+9WIJQclxkfaqiMdwnnlczPcRvR79iLVs/PvgIyFFEJKGfDyUcffaSdO3dGhAifz6fjx49HzP/000/V09Mjn893zvW8Xq+8Xu+gcY/HM+TGDWcunJGMPbf5c0YCIZfV9Q1HojxvkvE5bjP6HXtO93w4azn+OShnw8nhw4f1n//5n8rLy4vYX15ert7eXnV0dITHdu7cqVAopLKyMqfLAQAACWjYZ1BOnjypDz74ILx95MgRHTx4ULm5uSooKNDf/d3f6cCBA9q2bZsGBgbC7yvJzc1VWlqaxo8fr9tuu00PPPCANm3apGAwqEWLFmnevHlcwQMAACRdREDZv3+/br311vD22feGVFdXq6GhQa+88ookadKkSRG3e+ONN3TLLbdIkrZs2aJFixZp2rRpcrvdmjt3rtatW3eRDwEAACSbYQeUW265RcZ88eWM59t3Vm5urpqamoZ71wAA4DLBd/EAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOsMOKLt379add96pwsJCuVwubd26NWK/MUZLly5VQUGBMjIyVFFRocOHD0fM6enpUVVVlbKyspSTk6MFCxbo5MmTl/RAAABA8hh2QDl16pSuu+46bdiw4Zz7V69erXXr1mnTpk1qa2vTiBEjVFlZqdOnT4fnVFVV6Z133lFzc7O2bdum3bt3a+HChRf/KAAAQFJJHe4NZs6cqZkzZ55znzFGa9eu1eOPP67Zs2dLkp577jnl5+dr69atmjdvnt577z1t375d7e3tKi0tlSStX79et99+u370ox+psLDwEh4OAABIBsMOKOdz5MgRdXV1qaKiIjyWnZ2tsrIytba2at68eWptbVVOTk44nEhSRUWF3G632tradPfddw9aNxAIKBAIhLf9fr8kKRgMKhgMnrems/svNA/OSeaee1NMvEsYxOs2ET+Tge3PnWR+jtuIfsdetHo+nPUcDShdXV2SpPz8/Ijx/Pz88L6uri6NHj06sojUVOXm5obnfF5jY6OWLVs2aPz1119XZmbmkGprbm4e0jw4Jxl7vnpKvCv4YitKQ/EuwTGvvfZavEsYkmR8jtuMfsee0z3v7+8f8lxHA0q01NXVqba2Nrzt9/tVVFSkGTNmKCsr67y3DQaDam5u1vTp0+XxeKJdKpTcPZ/QsCPeJQzidRutKA2pfr9bgZAr3uU44lBDZbxLOK9kfo7biH7HXrR6fvYVkKFwNKD4fD5JUnd3twoKCsLj3d3dmjRpUnjO8ePHI2736aefqqenJ3z7z/N6vfJ6vYPGPR7PkBs3nLlwRjL2PDBgbwAIhFxW1zccifK8ScbnuM3od+w53fPhrOXo56CUlJTI5/OppaUlPOb3+9XW1qby8nJJUnl5uXp7e9XR0RGes3PnToVCIZWVlTlZDgAASFDDPoNy8uRJffDBB+HtI0eO6ODBg8rNzVVxcbEWL16sJ554QmPHjlVJSYnq6+tVWFioOXPmSJLGjx+v2267TQ888IA2bdqkYDCoRYsWad68eVzBAwAAJF1EQNm/f79uvfXW8PbZ94ZUV1fr2Wef1SOPPKJTp05p4cKF6u3t1c0336zt27crPT09fJstW7Zo0aJFmjZtmtxut+bOnat169Y58HAAAEAyGHZAueWWW2TMF1/O6HK5tHz5ci1fvvwL5+Tm5qqpqWm4dw0AAC4TfBcPAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrpMa7AFy+xiz5VbxLAABYijMoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADr8DkoAKxj+2fkeFOMVk+RJjTsUGDAJUn6n1Wz4lwVkFw4gwIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB3HA8rAwIDq6+tVUlKijIwMfelLX9KKFStkjAnPMcZo6dKlKigoUEZGhioqKnT48GGnSwEAAAnK8YDy5JNPauPGjXrqqaf03nvv6cknn9Tq1au1fv368JzVq1dr3bp12rRpk9ra2jRixAhVVlbq9OnTTpcDAAASkOMf1Pbmm29q9uzZmjXrzx9aNGbMGP385z/Xvn37JP357MnatWv1+OOPa/bs2ZKk5557Tvn5+dq6davmzZvndEkAACDBOB5QbrrpJj399NN6//339dd//dd6++23tWfPHq1Zs0aSdOTIEXV1damioiJ8m+zsbJWVlam1tfWcASUQCCgQCIS3/X6/JCkYDCoYDJ63nrP7LzQPzhlqz70p5rz7MTRet4n4ieg7V885xkQPx/HYi1bPh7Oey3z2zSEOCIVCeuyxx7R69WqlpKRoYGBAK1euVF1dnaQ/n2GZOnWqjh07poKCgvDt7r33XrlcLr3wwguD1mxoaNCyZcsGjTc1NSkzM9PJ8gEAQJT09/fr/vvvV19fn7Kyss471/EzKL/4xS+0ZcsWNTU16dprr9XBgwe1ePFiFRYWqrq6+qLWrKurU21tbXjb7/erqKhIM2bMuOADDAaDam5u1vTp0+XxeC7q/jE8Q+35hIYdMawqeXndRitKQ6rf71Yg5Ip3OZeFc/X8UENlnKtKXhzHYy9aPT/7CshQOB5Qvve972nJkiXhl2omTpyojz76SI2NjaqurpbP55MkdXd3R5xB6e7u1qRJk865ptfrldfrHTTu8XiG3LjhzIUzLtTzs1+yBmcEQi56GmOf7TnHl+jjOB57Tvd8OGs5fhVPf3+/3O7IZVNSUhQKhSRJJSUl8vl8amlpCe/3+/1qa2tTeXm50+UAAIAE5PgZlDvvvFMrV65UcXGxrr32Wr311ltas2aNvvnNb0qSXC6XFi9erCeeeEJjx45VSUmJ6uvrVVhYqDlz5jhdDgAASECOB5T169ervr5e3/nOd3T8+HEVFhbqn/7pn7R06dLwnEceeUSnTp3SwoUL1dvbq5tvvlnbt29Xenq60+UAAIAE5HhAGTVqlNauXau1a9d+4RyXy6Xly5dr+fLlTt89AABIAnwXDwAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKwTlYDyySef6Otf/7ry8vKUkZGhiRMnav/+/eH9xhgtXbpUBQUFysjIUEVFhQ4fPhyNUgAAQAJyPKD83//9n6ZOnSqPx6Nf//rXevfdd/Uv//IvuuKKK8JzVq9erXXr1mnTpk1qa2vTiBEjVFlZqdOnTztdDgAASECpTi/45JNPqqioSJs3bw6PlZSUhP9ujNHatWv1+OOPa/bs2ZKk5557Tvn5+dq6davmzZvndEkAACDBOH4G5ZVXXlFpaam+9rWvafTo0br++uv1zDPPhPcfOXJEXV1dqqioCI9lZ2errKxMra2tTpcDAAASkONnUD788ENt3LhRtbW1euyxx9Te3q4HH3xQaWlpqq6uVldXlyQpPz8/4nb5+fnhfZ8XCAQUCATC236/X5IUDAYVDAbPW8/Z/ReaB+cMtefeFBOLcpKe120ifiL6ztVzjjHRw3E89qLV8+Gs5zLGOHpUS0tLU2lpqd58883w2IMPPqj29na1trbqzTff1NSpU3Xs2DEVFBSE59x7771yuVx64YUXBq3Z0NCgZcuWDRpvampSZmamk+UDAIAo6e/v1/3336++vj5lZWWdd67jZ1AKCgp0zTXXRIyNHz9e//Ef/yFJ8vl8kqTu7u6IgNLd3a1Jkyadc826ujrV1taGt/1+v4qKijRjxowLPsBgMKjm5mZNnz5dHo/nYh4ShmmoPZ/QsCOGVSUvr9toRWlI9fvdCoRc8S7nsnCunh9qqIxzVcmL43jsRavnZ18BGQrHA8rUqVPV2dkZMfb+++/r6quvlvTnN8z6fD61tLSEA4nf71dbW5u+/e1vn3NNr9crr9c7aNzj8Qy5ccOZC2dcqOeBAX6ZOikQctHTGPtszzm+RB/H8dhzuufDWcvxgPLwww/rpptu0g9/+EPde++92rdvn55++mk9/fTTkiSXy6XFixfriSee0NixY1VSUqL6+noVFhZqzpw5TpcDAAASkOMB5YYbbtDLL7+suro6LV++XCUlJVq7dq2qqqrCcx555BGdOnVKCxcuVG9vr26++WZt375d6enpTpcDAAASkOMBRZLuuOMO3XHHHV+43+Vyafny5Vq+fHk07h4AACQ4vosHAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsE5qvAuAM8Ys+VW8SwjzphitniJNaNihwIAr3uUAABIQZ1AAAIB1CCgAAMA6BBQAAGCdqAeUVatWyeVyafHixeGx06dPq6amRnl5eRo5cqTmzp2r7u7uaJcCAAASRFQDSnt7u/7t3/5NX/7ylyPGH374Yb366qt68cUXtWvXLh07dkz33HNPNEsBAAAJJGoB5eTJk6qqqtIzzzyjK664Ijze19enn/70p1qzZo2++tWvavLkydq8ebPefPNN7d27N1rlAACABBK1y4xramo0a9YsVVRU6IknngiPd3R0KBgMqqKiIjw2btw4FRcXq7W1VTfeeOOgtQKBgAKBQHjb7/dLkoLBoILB4HnrOLv/QvMSnTfFxLuEMK/bRPxEdNHv2DtXz5P9GBNPl8tx3CbR6vlw1otKQHn++ed14MABtbe3D9rX1dWltLQ05eTkRIzn5+erq6vrnOs1NjZq2bJlg8Zff/11ZWZmDqmm5ubmIc1LVKunxLuCwVaUhuJdwmWFfsfeZ3v+2muvxbGSy0OyH8dt5HTP+/v7hzzX8YDy8ccf66GHHlJzc7PS09MdWbOurk61tbXhbb/fr6KiIs2YMUNZWVnnvW0wGFRzc7OmT58uj8fjSD02mtCwI94lhHndRitKQ6rf71YgxAe1RRv9jr1z9fxQQ2Wcq0pel8tx3CbR6vnZV0CGwvGA0tHRoePHj+srX/lKeGxgYEC7d+/WU089pR07dujMmTPq7e2NOIvS3d0tn893zjW9Xq+8Xu+gcY/HM+TGDWduIrLxE1sDIZeVdSUr+h17n+15Mh9fbJHsx3EbOd3z4azleECZNm2afvvb30aMzZ8/X+PGjdOjjz6qoqIieTwetbS0aO7cuZKkzs5OHT16VOXl5U6XAwAAEpDjAWXUqFGaMGFCxNiIESOUl5cXHl+wYIFqa2uVm5urrKwsffe731V5efk53yALAAAuP3H5ssAf//jHcrvdmjt3rgKBgCorK/WTn/wkHqUAAAALxSSg/OY3v4nYTk9P14YNG7Rhw4ZY3D0AAEgwfBcPAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6qfEuAACSwZglv4p3CcP2P6tmxbsE4AtxBgUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6zgeUBobG3XDDTdo1KhRGj16tObMmaPOzs6IOadPn1ZNTY3y8vI0cuRIzZ07V93d3U6XAgAAEpTjAWXXrl2qqanR3r171dzcrGAwqBkzZujUqVPhOQ8//LBeffVVvfjii9q1a5eOHTume+65x+lSAABAgkp1esHt27dHbD/77LMaPXq0Ojo69Dd/8zfq6+vTT3/6UzU1NemrX/2qJGnz5s0aP3689u7dqxtvvNHpkgAAQIJxPKB8Xl9fnyQpNzdXktTR0aFgMKiKiorwnHHjxqm4uFitra3nDCiBQECBQCC87ff7JUnBYFDBYPC89392/4XmJTpviol3CWFet4n4ieii37GXLD1PlOPi5XIct0m0ej6c9VzGmKj9DwuFQrrrrrvU29urPXv2SJKampo0f/78iMAhSVOmTNGtt96qJ598ctA6DQ0NWrZs2aDxpqYmZWZmRqd4AADgqP7+ft1///3q6+tTVlbWeedG9QxKTU2NDh06FA4nF6uurk61tbXhbb/fr6KiIs2YMeOCDzAYDKq5uVnTp0+Xx+O5pDpsNqFhR7xLCPO6jVaUhlS/361AyBXvcpIe/Y69ZOn5oYbKeJcwJJfLcdwm0er52VdAhiJqAWXRokXatm2bdu/erauuuio87vP5dObMGfX29ionJyc83t3dLZ/Pd861vF6vvF7voHGPxzPkxg1nbiIKDNh3kAyEXFbWlazod+wles8T7ZiY7MdxGznd8+Gs5fhVPMYYLVq0SC+//LJ27typkpKSiP2TJ0+Wx+NRS0tLeKyzs1NHjx5VeXm50+UAAIAE5PgZlJqaGjU1NemXv/ylRo0apa6uLklSdna2MjIylJ2drQULFqi2tla5ubnKysrSd7/7XZWXl3MFDwAAkBSFgLJx40ZJ0i233BIxvnnzZn3jG9+QJP34xz+W2+3W3LlzFQgEVFlZqZ/85CdOlwIAABKU4wFlKBcFpaena8OGDdqwYYPTdw8AAJIA38UDAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwTmq8C7DRmCW/incJAABc1jiDAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADW4aPuAeAylShf6+FNMVo9RZrQsEOdK++IdzmIEc6gAAAA6xBQAACAdQgoAADAOgQUAABgHd4kCwBIGInyxt5Ed/aNyfHEGRQAAGAdAgoAALAOAQUAAFgnrgFlw4YNGjNmjNLT01VWVqZ9+/bFsxwAAGCJuAWUF154QbW1tfrBD36gAwcO6LrrrlNlZaWOHz8er5IAAIAl4hZQ1qxZowceeEDz58/XNddco02bNikzM1M/+9nP4lUSAACwRFwuMz5z5ow6OjpUV1cXHnO73aqoqFBra+ug+YFAQIFAILzd19cnSerp6VEwGDzvfQWDQfX39+uPf/yjPB7PkOpL/fTUkObh3FJDRv39IaUG3RoIueJdTtKj37FHz2OLfsfe2Z4P53fnUJw4cUKSZIy5cA2O3esw/OEPf9DAwIDy8/MjxvPz8/W73/1u0PzGxkYtW7Zs0HhJSUnUasSluT/eBVxm6Hfs0fPYot+xF82enzhxQtnZ2eedkxAf1FZXV6fa2trwdigUUk9Pj/Ly8uRynT9N+/1+FRUV6eOPP1ZWVla0S4XoeazR79ij57FFv2MvWj03xujEiRMqLCy84Ny4BJQrr7xSKSkp6u7ujhjv7u6Wz+cbNN/r9crr9UaM5eTkDOs+s7KyeGLHGD2PLfode/Q8tuh37EWj5xc6c3JWXN4km5aWpsmTJ6ulpSU8FgqF1NLSovLy8niUBAAALBK3l3hqa2tVXV2t0tJSTZkyRWvXrtWpU6c0f/78eJUEAAAsEbeA8vd///f63//9Xy1dulRdXV2aNGmStm/fPuiNs5fK6/XqBz/4waCXiBA99Dy26Hfs0fPYot+xZ0PPXWYo1/oAAADEEN/FAwAArENAAQAA1iGgAAAA6xBQAACAdZI+oGzYsEFjxoxRenq6ysrKtG/fvniXlBQaGxt1ww03aNSoURo9erTmzJmjzs7OiDmnT59WTU2N8vLyNHLkSM2dO3fQh/Ph4qxatUoul0uLFy8Oj9Fv533yySf6+te/rry8PGVkZGjixInav39/eL8xRkuXLlVBQYEyMjJUUVGhw4cPx7HixDUwMKD6+nqVlJQoIyNDX/rSl7RixYqI72yh35dm9+7duvPOO1VYWCiXy6WtW7dG7B9Kf3t6elRVVaWsrCzl5ORowYIFOnnyZHQKNkns+eefN2lpaeZnP/uZeeedd8wDDzxgcnJyTHd3d7xLS3iVlZVm8+bN5tChQ+bgwYPm9ttvN8XFxebkyZPhOd/61rdMUVGRaWlpMfv37zc33nijuemmm+JYdXLYt2+fGTNmjPnyl79sHnroofA4/XZWT0+Pufrqq803vvEN09bWZj788EOzY8cO88EHH4TnrFq1ymRnZ5utW7eat99+29x1112mpKTE/OlPf4pj5Ylp5cqVJi8vz2zbts0cOXLEvPjii2bkyJHmX//1X8Nz6Pelee2118z3v/9989JLLxlJ5uWXX47YP5T+3nbbbea6664ze/fuNf/1X/9l/uqv/srcd999Uak3qQPKlClTTE1NTXh7YGDAFBYWmsbGxjhWlZyOHz9uJJldu3YZY4zp7e01Ho/HvPjii+E57733npFkWltb41Vmwjtx4oQZO3asaW5uNn/7t38bDij023mPPvqoufnmm79wfygUMj6fz/zzP/9zeKy3t9d4vV7z85//PBYlJpVZs2aZb37zmxFj99xzj6mqqjLG0G+nfT6gDKW/7777rpFk2tvbw3N+/etfG5fLZT755BPHa0zal3jOnDmjjo4OVVRUhMfcbrcqKirU2toax8qSU19fnyQpNzdXktTR0aFgMBjR/3Hjxqm4uJj+X4KamhrNmjUroq8S/Y6GV155RaWlpfra176m0aNH6/rrr9czzzwT3n/kyBF1dXVF9Dw7O1tlZWX0/CLcdNNNamlp0fvvvy9Jevvtt7Vnzx7NnDlTEv2OtqH0t7W1VTk5OSotLQ3PqaiokNvtVltbm+M1JcS3GV+MP/zhDxoYGBj0ybT5+fn63e9+F6eqklMoFNLixYs1depUTZgwQZLU1dWltLS0QV/qmJ+fr66urjhUmfief/55HThwQO3t7YP20W/nffjhh9q4caNqa2v12GOPqb29XQ8++KDS0tJUXV0d7uu5jjH0fPiWLFkiv9+vcePGKSUlRQMDA1q5cqWqqqokiX5H2VD629XVpdGjR0fsT01NVW5ublT+DZI2oCB2ampqdOjQIe3ZsyfepSStjz/+WA899JCam5uVnp4e73IuC6FQSKWlpfrhD38oSbr++ut16NAhbdq0SdXV1XGuLvn84he/0JYtW9TU1KRrr71WBw8e1OLFi1VYWEi/L1NJ+xLPlVdeqZSUlEFXMXR3d8vn88WpquSzaNEibdu2TW+88Yauuuqq8LjP59OZM2fU29sbMZ/+X5yOjg4dP35cX/nKV5SamqrU1FTt2rVL69atU2pqqvLz8+m3wwoKCnTNNddEjI0fP15Hjx6VpHBfOcY443vf+56WLFmiefPmaeLEifqHf/gHPfzww2psbJREv6NtKP31+Xw6fvx4xP5PP/1UPT09Ufk3SNqAkpaWpsmTJ6ulpSU8FgqF1NLSovLy8jhWlhyMMVq0aJFefvll7dy5UyUlJRH7J0+eLI/HE9H/zs5OHT16lP5fhGnTpum3v/2tDh48GP5TWlqqqqqq8N/pt7OmTp066NL5999/X1dffbUkqaSkRD6fL6Lnfr9fbW1t9Pwi9Pf3y+2O/JWUkpKiUCgkiX5H21D6W15ert7eXnV0dITn7Ny5U6FQSGVlZc4X5fjbbi3y/PPPG6/Xa5599lnz7rvvmoULF5qcnBzT1dUV79IS3re//W2TnZ1tfvOb35jf//734T/9/f3hOd/61rdMcXGx2blzp9m/f78pLy835eXlcaw6uXz2Kh5j6LfT9u3bZ1JTU83KlSvN4cOHzZYtW0xmZqb593//9/CcVatWmZycHPPLX/7S/Pd//7eZPXs2l71epOrqavMXf/EX4cuMX3rpJXPllVeaRx55JDyHfl+aEydOmLfeesu89dZbRpJZs2aNeeutt8xHH31kjBlaf2+77TZz/fXXm7a2NrNnzx4zduxYLjO+WOvXrzfFxcUmLS3NTJkyxezduzfeJSUFSef8s3nz5vCcP/3pT+Y73/mOueKKK0xmZqa5++67ze9///v4FZ1kPh9Q6LfzXn31VTNhwgTj9XrNuHHjzNNPPx2xPxQKmfr6epOfn2+8Xq+ZNm2a6ezsjFO1ic3v95uHHnrIFBcXm/T0dPOXf/mX5vvf/74JBALhOfT70rzxxhvnPG5XV1cbY4bW3z/+8Y/mvvvuMyNHjjRZWVlm/vz55sSJE1Gp12XMZz6mDwAAwAJJ+x4UAACQuAgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALDO/wN22BPssZ7HegAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your dataframe\n",
    "# Plotting the distribution of popularity scores\n",
    "df_model['popularity_score_scaled'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Define the bin edges for the categories based on the provided ranges\n",
    "bins = [-np.inf, 30, 50, 60, np.inf]\n",
    "labels = ['Not_so_popular', 'Popular_During', 'Semi_Popular', 'Popular_Forever']\n",
    "\n",
    "# Create a new categorical column\n",
    "df_model['popularity_category'] = pd.cut(df_model['popularity_score_scaled'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>tempo</th>\n",
       "      <th>mean_zcr</th>\n",
       "      <th>median_zcr</th>\n",
       "      <th>std_zcr</th>\n",
       "      <th>max_zcr</th>\n",
       "      <th>aboveThr_zcr</th>\n",
       "      <th>mean_sc</th>\n",
       "      <th>median_sc</th>\n",
       "      <th>std_sc</th>\n",
       "      <th>...</th>\n",
       "      <th>Tone2</th>\n",
       "      <th>Tone3</th>\n",
       "      <th>Tone4</th>\n",
       "      <th>Tone5</th>\n",
       "      <th>Tone6</th>\n",
       "      <th>Tone_deltaMean</th>\n",
       "      <th>Tone_avg_sd</th>\n",
       "      <th>popularity_score_scaled</th>\n",
       "      <th>time_frame</th>\n",
       "      <th>popularity_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0800 HEAVEN</td>\n",
       "      <td>143.554688</td>\n",
       "      <td>0.0918</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.6323</td>\n",
       "      <td>0.4358</td>\n",
       "      <td>2196.7699</td>\n",
       "      <td>2259.6592</td>\n",
       "      <td>862.0266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.009060</td>\n",
       "      <td>0.106067</td>\n",
       "      <td>53.814449</td>\n",
       "      <td>178.0</td>\n",
       "      <td>Semi_Popular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 2 3 feat Jason Derulo  De La Ghetto</td>\n",
       "      <td>95.703125</td>\n",
       "      <td>0.1278</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>0.6041</td>\n",
       "      <td>2811.9937</td>\n",
       "      <td>2768.6767</td>\n",
       "      <td>1057.0624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.008302</td>\n",
       "      <td>0.086733</td>\n",
       "      <td>54.638400</td>\n",
       "      <td>2117.0</td>\n",
       "      <td>Semi_Popular</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              track_name       tempo  mean_zcr  median_zcr  \\\n",
       "0                            0800 HEAVEN  143.554688    0.0918      0.0913   \n",
       "1  1 2 3 feat Jason Derulo  De La Ghetto   95.703125    0.1278      0.1172   \n",
       "\n",
       "   std_zcr  max_zcr  aboveThr_zcr    mean_sc  median_sc     std_sc  ...  \\\n",
       "0   0.0527   0.6323        0.4358  2196.7699  2259.6592   862.0266  ...   \n",
       "1   0.0813   0.6621        0.6041  2811.9937  2768.6767  1057.0624  ...   \n",
       "\n",
       "    Tone2   Tone3   Tone4   Tone5   Tone6  Tone_deltaMean  Tone_avg_sd  \\\n",
       "0  0.1248  0.1614  0.1270  0.0527  0.0522        0.009060     0.106067   \n",
       "1  0.0931  0.1172  0.1136  0.0526  0.0427        0.008302     0.086733   \n",
       "\n",
       "   popularity_score_scaled  time_frame  popularity_category  \n",
       "0                53.814449       178.0         Semi_Popular  \n",
       "1                54.638400      2117.0         Semi_Popular  \n",
       "\n",
       "[2 rows x 74 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PREPARING THE DATA\n",
    "\n",
    "# Features and target\n",
    "X = df_model.drop(['track_name', 'popularity_score_scaled', 'popularity_category'], axis=1)\n",
    "y = df_model['popularity_category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)\n",
    "\n",
    "df_scaled['popularity_category'] = y\n",
    "df_scaled['track_name'] = df_model['track_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SPLITTING THE DATASET\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For predicting the popularity category, which is now a classification problem, you can try a variety of machine learning models. Here's a list of commonly used classifiers, each with its own strengths and suitable use cases:\n",
    "\n",
    "1. Logistic Regression: A good baseline for classification problems. It's simple, fast, and effective for linearly separable classes.\n",
    "\n",
    "2. Decision Trees: They are easy to interpret and work well with categorical and numerical data. They can capture non-linear patterns but can overfit if not carefully tuned.\n",
    "\n",
    "3. Random Forest: An ensemble of decision trees that can capture complex relationships in the data. It's robust to overfitting and works well with a mix of features but can be less interpretable due to its complexity.\n",
    "\n",
    "4. Gradient Boosting Machines (GBM): Another ensemble method that's effective in predictive accuracy and robustness. Models like XGBoost, LightGBM, and CatBoost fall under this category and are known for winning many Kaggle competitions.\n",
    "\n",
    "5. Support Vector Machines (SVM): Effective in high-dimensional spaces and best suited for problems with clear margin of separation. It can be computationally intensive, especially with large datasets.\n",
    "\n",
    "6. K-Nearest Neighbors (KNN): A non-parametric method that is simple and effective, especially if you have a small dataset. However, it can be slow and is sensitive to irrelevant features and the scale of the data.\n",
    "\n",
    "7. Neural Networks: They can model complex and non-linear relationships. Deep learning models may be suitable if you have a large amount of data and computational resources.\n",
    "\n",
    "8. Naive Bayes: It's based on Bayes' theorem and works particularly well for large feature spaces like text classification. It assumes independence between predictors, which may not be the case in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42718446601941745\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " Not_so_popular       0.47      0.32      0.38        25\n",
      " Popular_During       0.47      0.67      0.55        51\n",
      "Popular_Forever       0.00      0.00      0.00         8\n",
      "   Semi_Popular       0.20      0.11      0.14        19\n",
      "\n",
      "       accuracy                           0.43       103\n",
      "      macro avg       0.29      0.27      0.27       103\n",
      "   weighted avg       0.38      0.43      0.39       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################### LOGISTIC REGRESSION ######################################################\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=1000)  # Increased max_iter for convergence\n",
    "\n",
    "# Fit the model on the training data\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output indicates that the Logistic Regression model achieved an overall accuracy of 42.7% on test data, which suggests it performs better than random guessing but is still not highly accurate. The precision, recall, and f1-score for each class provide additional insight into the model's performance:\n",
    "\n",
    "Not_so_popular: Has a precision of 0.47 and recall of 0.32, indicating that the model is relatively conservative when predicting this class; it's correct less than half the time when it does predict this class, and it identifies 32% of all actual instances of this class.\n",
    "\n",
    "Popular_During: This category has the best f1-score at 0.55 with a precision of 0.47 and a recall of 0.67, suggesting that the model is more confident and accurate in predicting this class than the others.\n",
    "\n",
    "Popular_Forever: The model did not correctly predict any instances of this class (precision and recall are both 0). This could be due to a lack of representative features that differentiate this class well, or it might be that this class is underrepresented in the dataset.\n",
    "\n",
    "Semi_Popular: It seems there is a fourth category in the output that wasn't mentioned before. For this category, the model has a precision of 0.20 and recall of 0.11, indicating poor performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_model['popularity_category'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class imbalance is a common issue in machine learning classification problems and can lead to poor model performance, especially for the minority class. \n",
    "Techniques like SMOTE for oversampling, class weights during training, or collecting more data can help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X_scaled is your feature set and y is the target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE()\n",
    "\n",
    "# Fit SMOTE to the training data\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.34951456310679613\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " Not_so_popular       0.43      0.40      0.42        25\n",
      " Popular_During       0.50      0.39      0.44        51\n",
      "Popular_Forever       0.15      0.25      0.19         8\n",
      "   Semi_Popular       0.15      0.21      0.17        19\n",
      "\n",
      "       accuracy                           0.35       103\n",
      "      macro avg       0.31      0.31      0.31       103\n",
      "   weighted avg       0.39      0.35      0.37       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################### LOGISTIC REGRESSION ######################################################\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=1000)  # Increased max_iter for convergence\n",
    "\n",
    "# Fit the model on the training data\n",
    "log_reg.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the new results, the precision and recall for the \"Popular_Forever\" and \"Semi_Popular\" categories have indeed increased, which means the model is now better at identifying these previously under-represented classes. This is an indication that the balancing technique is having the desired effect on the model's ability to classify the minority classes.\n",
    "\n",
    "When dealing with imbalanced datasets, overall accuracy is not always the best metric to focus on. Instead, look at metrics such as:<br/>\n",
    "\n",
    "Recall: The ability of the classifier to find all the positive samples.<br/>\n",
    "Precision: How many of the items identified as positive are actually positive.<br/>\n",
    "F1 Score: The harmonic mean of precision and recall.<br/>\n",
    "These metrics provide a better sense of how well the model is performing across all classes. It seems that the balancing helped improve these for the minority class.<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy: 0.5145631067961165\n",
      "Random Forest Classifier Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " Not_so_popular       0.58      0.44      0.50        25\n",
      " Popular_During       0.56      0.71      0.63        51\n",
      "Popular_Forever       0.00      0.00      0.00         8\n",
      "   Semi_Popular       0.38      0.32      0.34        19\n",
      "\n",
      "       accuracy                           0.51       103\n",
      "      macro avg       0.38      0.37      0.37       103\n",
      "   weighted avg       0.49      0.51      0.49       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################################################################################## RANDOM FOREST CLASSIFIER ##############################################################################################################\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Random Forest Classifier Accuracy:\", accuracy_rf)\n",
    "print(\"Random Forest Classifier Classification Report:\")\n",
    "print(report_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tune the hyper parameters for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best Score: 0.81067511129469\n",
      "Best Random Forest Classifier Accuracy: 0.4174757281553398\n",
      "Best Random Forest Classifier Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " Not_so_popular       0.47      0.32      0.38        25\n",
      " Popular_During       0.50      0.63      0.56        51\n",
      "Popular_Forever       0.00      0.00      0.00         8\n",
      "   Semi_Popular       0.19      0.16      0.17        19\n",
      "\n",
      "       accuracy                           0.42       103\n",
      "      macro avg       0.29      0.28      0.28       103\n",
      "   weighted avg       0.40      0.42      0.40       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize the grid search model\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "\n",
    "# Use the best estimator for making predictions\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "accuracy_best_rf = accuracy_score(y_test, y_pred_best_rf)\n",
    "report_best_rf = classification_report(y_test, y_pred_best_rf)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Best Random Forest Classifier Accuracy:\", accuracy_best_rf)\n",
    "print(\"Best Random Forest Classifier Classification Report:\")\n",
    "print(report_best_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, it seems that after hyperparameter tuning, the accuracy on the test set has decreased to approximately 41.7%, down from 51.5%. This can happen for several reasons:\n",
    "\n",
    "Overfitting during Training: The best parameters found during grid search may have overfitted to the training data, especially since the training data was augmented using SMOTE. This can lead to an artificially high score during training that doesn't generalize well to the test data.\n",
    "\n",
    "Cross-validation Discrepancy: The best score from grid search is based on cross-validation on the training set, which can sometimes give an optimistic estimate of the model's performance on unseen data.\n",
    "\n",
    "Difference in Data Distribution: There could be a difference in the distribution of data between the training set and the test set, even with stratification. This can affect the model's performance.\n",
    "\n",
    "Evaluation Metrics: The grid search optimization focused on maximizing the cross-validation score, which by default for classifiers in sklearn is accuracy. If the dataset is imbalanced, optimizing for accuracy may not lead to the best model for all classes, as we see with the 'Popular_Forever' class.\n",
    "\n",
    "Here are some steps you can take to potentially improve the performance:\n",
    "\n",
    "Optimize for a Different Metric: If certain classes are more important, or you want to ensure balance across classes, consider optimizing for a different metric such as F1-score.\n",
    "\n",
    "Review the Training Process: Check for overfitting during training by comparing training scores with validation scores.\n",
    "\n",
    "Adjust the Grid: The range of hyperparameters in the grid might need adjustment. For example, you might need to explore deeper trees or different values for min_samples_split.\n",
    "\n",
    "Feature Engineering: Continue to refine the input features. Feature selection or extraction might yield a more informative set of inputs for the model.\n",
    "\n",
    "Model Complexity: If the model is too complex, it might overfit; if it's too simple, it might underfit. Adjust the complexity with hyperparameters, or try different models.\n",
    "\n",
    "Different Model: Since Random Forest has not performed as expected, consider trying a different model like Gradient Boosting or XGBoost, which can be more robust to class imbalance and might perform better.\n",
    "\n",
    "It's also worth noting that while accuracy is a useful metric, it's not the only measure of success, especially with imbalanced classes. Look at the precision, recall, and F1 scores for each class to get a better understanding of your model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier Accuracy: 0.4854368932038835\n",
      "KNN Classifier Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " Not_so_popular       0.32      0.24      0.27        25\n",
      " Popular_During       0.53      0.76      0.63        51\n",
      "Popular_Forever       0.00      0.00      0.00         8\n",
      "   Semi_Popular       0.50      0.26      0.34        19\n",
      "\n",
      "       accuracy                           0.49       103\n",
      "      macro avg       0.34      0.32      0.31       103\n",
      "   weighted avg       0.43      0.49      0.44       103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize the KNeighborsClassifier\n",
    "# n_neighbors is a hyperparameter that you can tune. Starting with 5.\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "report_knn = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"KNN Classifier Accuracy:\", accuracy_knn)\n",
    "print(\"KNN Classifier Classification Report:\")\n",
    "print(report_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/Cast' defined at (most recent call last):\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 978, in launch_instance\n      app.start()\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\megha\\AppData\\Local\\Temp\\ipykernel_11520\\1936361519.py\", line 15, in <module>\n      history = model.fit(X_train_smote, y_train_smote, validation_split=0.1, epochs=150, batch_size=10, verbose=1)\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 2078, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py\", line 5610, in sparse_categorical_crossentropy\n      target = cast(target, \"int64\")\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py\", line 2304, in cast\n      return tf.cast(x, dtype)\nNode: 'sparse_categorical_crossentropy/Cast'\nCast string to int64 is not supported\n\t [[{{node sparse_categorical_crossentropy/Cast}}]] [Op:__inference_train_function_978]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\megha\\Documents\\Sem3\\881 Data Mining\\Project\\Final\\Mine\\Popularity Model\\Final_Models.ipynb Cell 29\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/megha/Documents/Sem3/881%20Data%20Mining/Project/Final/Mine/Popularity%20Model/Final_Models.ipynb#X63sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m), metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/megha/Documents/Sem3/881%20Data%20Mining/Project/Final/Mine/Popularity%20Model/Final_Models.ipynb#X63sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Fit the model on the training data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/megha/Documents/Sem3/881%20Data%20Mining/Project/Final/Mine/Popularity%20Model/Final_Models.ipynb#X63sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(X_train_smote, y_train_smote, validation_split\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m150\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/megha/Documents/Sem3/881%20Data%20Mining/Project/Final/Mine/Popularity%20Model/Final_Models.ipynb#X63sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Evaluate the model on the test data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/megha/Documents/Sem3/881%20Data%20Mining/Project/Final/Mine/Popularity%20Model/Final_Models.ipynb#X63sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32mc:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/Cast' defined at (most recent call last):\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 978, in launch_instance\n      app.start()\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\megha\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\megha\\AppData\\Local\\Temp\\ipykernel_11520\\1936361519.py\", line 15, in <module>\n      history = model.fit(X_train_smote, y_train_smote, validation_split=0.1, epochs=150, batch_size=10, verbose=1)\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py\", line 2078, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py\", line 5610, in sparse_categorical_crossentropy\n      target = cast(target, \"int64\")\n    File \"c:\\Users\\megha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py\", line 2304, in cast\n      return tf.cast(x, dtype)\nNode: 'sparse_categorical_crossentropy/Cast'\nCast string to int64 is not supported\n\t [[{{node sparse_categorical_crossentropy/Cast}}]] [Op:__inference_train_function_978]"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=X_train_smote.shape[1], activation='relu'))  # First hidden layer with 12 neurons\n",
    "model.add(Dense(8, activation='relu'))  # Second hidden layer with 8 neurons\n",
    "model.add(Dense(4, activation='softmax'))  # Output layer with 4 neurons since we have 4 classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# Fit the model on the training data\n",
    "history = model.fit(X_train_smote, y_train_smote, validation_split=0.1, epochs=150, batch_size=10, verbose=1)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Neural Network Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Selection<br/>\n",
    "Try different algorithms to see which performs best. Common choices for regression problems include:<br/>\n",
    "\n",
    "Linear Regression<br/>\n",
    "Decision Tree Regression<br/>\n",
    "Random Forest Regression<br/>\n",
    "Gradient Boosting Machines (like XGBoost or LightGBM)<br/>\n",
    "Support Vector Machines (SVM)<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression trained.\n",
      "Random Forest trained.\n",
      "Support Vector Machine trained.\n",
      "XGBoost trained.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"Support Vector Machine\": SVR(),\n",
    "    \"XGBoost\": XGBRegressor()\n",
    "}\n",
    "\n",
    "# Train models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"{name} trained.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - MSE: 232.2233027153926, R2: 0.046319133218791886\n",
      "Random Forest - MSE: 179.32754567529133, R2: 0.2635482865087052\n",
      "Support Vector Machine - MSE: 239.72273652360624, R2: 0.015520903881097503\n",
      "XGBoost - MSE: 208.5506806497821, R2: 0.1435364514919032\n"
     ]
    }
   ],
   "source": [
    "### MODEL EVALUATION\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"{name} - MSE: {mse}, R2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regressor:\n",
    "- MSE: 188.11\n",
    "- R2: 0.227\n",
    "\n",
    "This model has the lowest MSE and the highest R² score, indicating it's the best at predicting the 'popularity_score_scaled' among the models you tested.\n",
    "Linear Regression and Support Vector Machine:\n",
    "\n",
    "These models have higher MSEs and lower R² scores, suggesting they're not capturing the complexity of your data as effectively as the Random Forest.\n",
    "XGBoost:<br/>\n",
    "\n",
    "XGBoost shows a decent performance but is still outperformed by the Random Forest. It might improve with hyperparameter tuning.<br/>\n",
    "Next Steps:<br/>\n",
    "1. Hyperparameter Tuning:<br/>\n",
    "The performance of the Random Forest and XGBoost models might be significantly improved by tuning their hyperparameters. You can use techniques like Grid Search or Random Search for this purpose.\n",
    "2. Feature Importance Analysis:<br/>\n",
    "Especially for the Random Forest and XGBoost models, check which features are most important for predicting popularity. This could provide insights into your dataset and might even suggest further feature engineering or selection.\n",
    "3. Cross-Validation:<br/>\n",
    "Consider using cross-validation to assess the model's performance. This will give you a more robust understanding of how well the model might perform on unseen data.\n",
    "4. Model Refinement:<br/>\n",
    "Based on the results of hyperparameter tuning and feature importance, refine your models. You may also want to revisit data preprocessing steps if you think there's more room for improvement.\n",
    "5. Final Model Selection:<br/>\n",
    "Once you've tuned the models and reassessed their performance, choose the one that shows the best results on your test data for your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    }
   ],
   "source": [
    "###### RUNNING ON COLLAB\n",
    "\"\"\"\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [10, 20, 30, 40, 50, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = param_grid, \n",
    "                               n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters:\", rf_random.best_params_)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'colsample_bytree': [0.3, 0.5, 0.7, 0.9, 1],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1]\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "xgb_random = RandomizedSearchCV(estimator = xgb, param_distributions = param_grid, \n",
    "                                n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "xgb_random.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters:\", xgb_random.best_params_)\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
