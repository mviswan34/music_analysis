{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"Popular_Clean.csv\")\n",
    "df2 = pd.read_csv(\"Song_Analytics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>...</th>\n",
       "      <th>highest_peak_value</th>\n",
       "      <th>normalized_likes</th>\n",
       "      <th>normalized_views</th>\n",
       "      <th>normalized_us_hit</th>\n",
       "      <th>normalized_high_peak</th>\n",
       "      <th>likes_per_day</th>\n",
       "      <th>views_per_day</th>\n",
       "      <th>genre_averaged_likes</th>\n",
       "      <th>normalized_num_peak_periods</th>\n",
       "      <th>popularity_score_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.00146</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>0.334</td>\n",
       "      <td>171.005</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>16.078045</td>\n",
       "      <td>20.463609</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>0.011874</td>\n",
       "      <td>0.015113</td>\n",
       "      <td>0.025767</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>43.660471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dance Monkey</td>\n",
       "      <td>Tones And I</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.0937</td>\n",
       "      <td>0.69000</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.514</td>\n",
       "      <td>98.029</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.554820</td>\n",
       "      <td>21.452550</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>0.014216</td>\n",
       "      <td>0.029205</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>41.465744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        track_name  artist_name  danceability  energy  speechiness  \\\n",
       "0  Blinding Lights   The Weeknd         0.514   0.730       0.0598   \n",
       "1     Dance Monkey  Tones And I         0.824   0.587       0.0937   \n",
       "\n",
       "   acousticness  instrumentalness  liveness  valence    tempo  ...  \\\n",
       "0       0.00146          0.000095    0.0897    0.334  171.005  ...   \n",
       "1       0.69000          0.000105    0.1490    0.514   98.029  ...   \n",
       "\n",
       "   highest_peak_value normalized_likes  normalized_views  normalized_us_hit  \\\n",
       "0               100.0        16.078045         20.463609           3.258097   \n",
       "1                12.0        16.554820         21.452550           2.484907   \n",
       "\n",
       "   normalized_high_peak likes_per_day views_per_day  genre_averaged_likes  \\\n",
       "0              4.615121      0.011874      0.015113              0.025767   \n",
       "1              2.564949      0.010971      0.014216              0.029205   \n",
       "\n",
       "  normalized_num_peak_periods  popularity_score_scaled  \n",
       "0                    0.333333                43.660471  \n",
       "1                    0.111111                41.465744  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>tempo</th>\n",
       "      <th>mean_zcr</th>\n",
       "      <th>median_zcr</th>\n",
       "      <th>std_zcr</th>\n",
       "      <th>max_zcr</th>\n",
       "      <th>aboveThr_zcr</th>\n",
       "      <th>mean_sc</th>\n",
       "      <th>median_sc</th>\n",
       "      <th>std_sc</th>\n",
       "      <th>...</th>\n",
       "      <th>contrast_del_mean</th>\n",
       "      <th>contrast_avg_sd</th>\n",
       "      <th>Tone1</th>\n",
       "      <th>Tone2</th>\n",
       "      <th>Tone3</th>\n",
       "      <th>Tone4</th>\n",
       "      <th>Tone5</th>\n",
       "      <th>Tone6</th>\n",
       "      <th>Tone_deltaMean</th>\n",
       "      <th>Tone_avg_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0800 HEAVEN</td>\n",
       "      <td>143.554688</td>\n",
       "      <td>0.0918</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.6323</td>\n",
       "      <td>0.4358</td>\n",
       "      <td>2196.7699</td>\n",
       "      <td>2259.6592</td>\n",
       "      <td>862.0266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6804</td>\n",
       "      <td>6.128429</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.009060</td>\n",
       "      <td>0.106067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 2 3 feat Jason Derulo  De La Ghetto</td>\n",
       "      <td>95.703125</td>\n",
       "      <td>0.1278</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>0.6041</td>\n",
       "      <td>2811.9937</td>\n",
       "      <td>2768.6767</td>\n",
       "      <td>1057.0624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7764</td>\n",
       "      <td>6.554386</td>\n",
       "      <td>0.1012</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.008302</td>\n",
       "      <td>0.086733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              track_name       tempo  mean_zcr  median_zcr  \\\n",
       "0                            0800 HEAVEN  143.554688    0.0918      0.0913   \n",
       "1  1 2 3 feat Jason Derulo  De La Ghetto   95.703125    0.1278      0.1172   \n",
       "\n",
       "   std_zcr  max_zcr  aboveThr_zcr    mean_sc  median_sc     std_sc  ...  \\\n",
       "0   0.0527   0.6323        0.4358  2196.7699  2259.6592   862.0266  ...   \n",
       "1   0.0813   0.6621        0.6041  2811.9937  2768.6767  1057.0624  ...   \n",
       "\n",
       "   contrast_del_mean  contrast_avg_sd   Tone1   Tone2   Tone3   Tone4   Tone5  \\\n",
       "0             0.6804         6.128429  0.1183  0.1248  0.1614  0.1270  0.0527   \n",
       "1             0.7764         6.554386  0.1012  0.0931  0.1172  0.1136  0.0526   \n",
       "\n",
       "    Tone6  Tone_deltaMean  Tone_avg_sd  \n",
       "0  0.0522        0.009060     0.106067  \n",
       "1  0.0427        0.008302     0.086733  \n",
       "\n",
       "[2 rows x 71 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging 'popularity_score_scaled' and 'time_frame' from df1 into df2\n",
    "df_model = df2.merge(df1[['track_name', 'popularity_score_scaled', 'time_frame']], \n",
    "                       on='track_name', \n",
    "                       how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_model.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PREPARING THE DATA\n",
    "\n",
    "# Features and target\n",
    "X = df_model.drop(['track_name', 'popularity_score_scaled'], axis=1)\n",
    "y = df_model['popularity_score_scaled']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SPLITTING THE DATASET\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Selection<br/>\n",
    "Try different algorithms to see which performs best. Common choices for regression problems include:<br/>\n",
    "\n",
    "Linear Regression<br/>\n",
    "Decision Tree Regression<br/>\n",
    "Random Forest Regression<br/>\n",
    "Gradient Boosting Machines (like XGBoost or LightGBM)<br/>\n",
    "Support Vector Machines (SVM)<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression trained.\n",
      "Random Forest trained.\n",
      "Support Vector Machine trained.\n",
      "XGBoost trained.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"Support Vector Machine\": SVR(),\n",
    "    \"XGBoost\": XGBRegressor()\n",
    "}\n",
    "\n",
    "# Train models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"{name} trained.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - MSE: 232.2233027153926, R2: 0.046319133218791886\n",
      "Random Forest - MSE: 188.11057073122677, R2: 0.22747868087325673\n",
      "Support Vector Machine - MSE: 239.72273652360624, R2: 0.015520903881097503\n",
      "XGBoost - MSE: 208.5506806497821, R2: 0.1435364514919032\n"
     ]
    }
   ],
   "source": [
    "### MODEL EVALUATION\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"{name} - MSE: {mse}, R2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regressor:\n",
    "- MSE: 188.11\n",
    "- R2: 0.227\n",
    "\n",
    "This model has the lowest MSE and the highest R² score, indicating it's the best at predicting the 'popularity_score_scaled' among the models you tested.\n",
    "Linear Regression and Support Vector Machine:\n",
    "\n",
    "These models have higher MSEs and lower R² scores, suggesting they're not capturing the complexity of your data as effectively as the Random Forest.\n",
    "XGBoost:<br/>\n",
    "\n",
    "XGBoost shows a decent performance but is still outperformed by the Random Forest. It might improve with hyperparameter tuning.<br/>\n",
    "Next Steps:<br/>\n",
    "1. Hyperparameter Tuning:<br/>\n",
    "The performance of the Random Forest and XGBoost models might be significantly improved by tuning their hyperparameters. You can use techniques like Grid Search or Random Search for this purpose.\n",
    "2. Feature Importance Analysis:<br/>\n",
    "Especially for the Random Forest and XGBoost models, check which features are most important for predicting popularity. This could provide insights into your dataset and might even suggest further feature engineering or selection.\n",
    "3. Cross-Validation:<br/>\n",
    "Consider using cross-validation to assess the model's performance. This will give you a more robust understanding of how well the model might perform on unseen data.\n",
    "4. Model Refinement:<br/>\n",
    "Based on the results of hyperparameter tuning and feature importance, refine your models. You may also want to revisit data preprocessing steps if you think there's more room for improvement.\n",
    "5. Final Model Selection:<br/>\n",
    "Once you've tuned the models and reassessed their performance, choose the one that shows the best results on your test data for your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [10, 20, 30, 40, 50, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = param_grid, \n",
    "                               n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters:\", rf_random.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'colsample_bytree': [0.3, 0.5, 0.7, 0.9, 1],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1]\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "xgb_random = RandomizedSearchCV(estimator = xgb, param_distributions = param_grid, \n",
    "                                n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "xgb_random.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters:\", xgb_random.best_params_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
